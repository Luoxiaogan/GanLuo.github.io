\section{Research Experience}
\begin{itemize}
    \item \heading{Convergence and Speedup Analysis of Distributed Optimization Algorithms}{Peking University}
          {Undergraduate Research Assistant}{Nov.\ 2023 -- Present}
          \begin{itemize}
              \item \detail{Advisor}{\href{https://kunyuan827.github.io}{Kun Yuan}}{}
              
              \item \textbf{Project 1: Analysis of Push-Pull Algorithm}
              \begin{itemize}
              \item \textbf{Push-Pull Algorithm Provably Achieves Linear
Speedup Over Arbitrary Network Topologies}\\
\href{https://lavaei.ieor.berkeley.edu/Group.html}{Liyuan Liang}*, \underline{Gan Luo}*,  \href{https://kunyuan827.github.io}{Kun Yuan} (*Equal contribution) [coming soon to Arxiv]
                  \item {\textbf{Currently finalizing this paper for submission to SIOPT.}}
                  \item {Conducted research on the \href{https://arxiv.org/pdf/1810.06653v4}{Push-Pull Algorithm}, focusing on convergence and linear speedup properties in non-convex and stochastic settings on arbitrary topology.}
                  \item First to prove convergence and linear speedup properties of the \href{https://arxiv.org/pdf/1810.06653v4}{Push-Pull Algorithm} under non-convex and stochastic settings  on arbitrary topology.
                  \item Validated the proposed theoretical results by conducting distributed optimization numerical experiments on the MNIST and CIFAR10 datasets.
              \end{itemize}
              
              \item \textbf{Project 2: Analysis on Decentralized
Optimization over Row-stochastic Networks}
              \begin{itemize}
              \item \textbf{Achieving Linear Speedup and Optimal Complexity for Decentralized Optimization over Row-stochastic Networks}\\
              \href{https://lavaei.ieor.berkeley.edu/Group.html}{Liyuan Liang}*, \href{https://openreview.net/profile?id=~Xinyi_Chen9}{Xinyi Chen}*, \underline{Gan Luo}*, \href{https://kunyuan827.github.io}{Kun Yuan} (*Equal contribution) \href{https://arxiv.org/pdf/2506.04600}{[Arxiv]}
                  \item {\textbf{Acceped to ICML2025, \textcolor{red}{Spotlight}}}
                  \item {Introduced effective metrics to capture the influence of row-stochastic mixing matrices}
                  \item {Established the first convergence lower bound for decentralized learning over row-stochastic networks}
                  \item {Incorporated a multi-step gossip (MG) protocol, to attain the lower bound, achieving optimal complexity.}
                  \item {Proposed a novel analysis framework demonstrating that \href{https://arxiv.org/pdf/1803.09169}{PULL-DIAG-GT} achieves linear speedup, which is the first such result for row-stochastic decentralized optimization.}
                  \item{Conducted numerical experiments to validate theoretical results.}
              \end{itemize}
          \end{itemize}

    \item \heading{Online Scheduling on LLM Inference}{Massachusetts Institute of Technology}
          {Undergraduate Research Assistant}{Oct.\ 2024 -- Present}
          \begin{itemize}
              \item \detail{Advisor}{\href{https://slevi1.mit.edu}{David Simchi-Levi}}{}
              \item \textbf{Project 1: Online Batching Algorithm on LLM Inference}
              \begin{itemize}
                \item \textbf{Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints}\\
    ($\alpha$-$\beta$) \href{https://www.mit.edu/~aorc/index.html}{Ruicheng Ao}*, \underline{Gan Luo}*, \href{https://slevi1.mit.edu}{David Simchi-Levi}, \href{https://www.columbia.edu/~xw2230/}{Xinshang Wang}, available on \href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5195463}{[SSRN]} and \href{https://arxiv.org/abs/2504.11320}{[Arxiv]}
                  \item {\textbf{This paper is submitted to Operations Research.}}
                  \item {Formulated the LLM inference as a multi-stage online scheduling task with stochastic queueable requests.}
                  \item {Proposed a novel online batching algorithm for LLM inference.}
                  \item {Proved that the algorithm achieves near-optimal throughput while controlling latency and Time to First Token (TTFT).}
                  \item {Conducted numerical experiments on synthetic and real-world datasets with Llama-7B on A100 GPU to validate theoretical results.}
              \end{itemize}
          \end{itemize}
          
          
\end{itemize}